{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# TODO: change ID\n",
    "ID = \"vae-v1-ddp\"\n",
    "\n",
    "# Distributed\n",
    "RANK = int(os.getenv(\"RANK\", 0))\n",
    "WORLD_SIZE = int(os.getenv(\"WORLD_SIZE\", 1))\n",
    "DISTRIBUTED = WORLD_SIZE > 1\n",
    "\n",
    "# Mixed precision\n",
    "MIXED_PRECISION = True\n",
    "\n",
    "# TODO: change device\n",
    "DEVICE = \"cuda\"\n",
    "DEVICE_ID = 1  # None for CPU\n",
    "DEVICE_IDS = [0, 1, 2, 3]\n",
    "OMP_NUM_THREADS = 10\n",
    "SEED = 42\n",
    "\n",
    "# Dataset\n",
    "DATASET_REPETITIONS = 1\n",
    "IMAGE_SIZE = 128\n",
    "\n",
    "# Model architecture\n",
    "LATENT_DIM = 4\n",
    "NUM_HEADS = 8\n",
    "VAE_SCALE = 2\n",
    "VAE_BETA = 0.5\n",
    "\n",
    "# Training\n",
    "# TODO: change epochs\n",
    "START_EPOCH = 0\n",
    "EPOCHS = 100\n",
    "PLOT_EVERY = 1\n",
    "BATCH_SIZE = 8 * WORLD_SIZE\n",
    "\n",
    "LEARNING_RATE = 1e-4\n",
    "WEIGHT_DECAY = 1e-5\n",
    "\n",
    "# Dataset\n",
    "DS_PATH = \"./dataset\"\n",
    "DS_IMAGE_PATH = DS_PATH\n",
    "DS_ID2WORD_PATH = os.path.join(DS_PATH, \"dictionary/id2Word.npy\")\n",
    "DS_VOCAB_PATH = os.path.join(DS_PATH, \"dictionary/vocab.npy\")\n",
    "DS_WORD2ID_PATH = os.path.join(DS_PATH, \"dictionary/word2Id.npy\")\n",
    "DS_TEXT2IMG_PATH = os.path.join(DS_PATH, \"dataset/text2ImgData.pkl\")\n",
    "DS_TEST_DATA_PATH = os.path.join(DS_PATH, \"dataset/testData.pkl\")\n",
    "\n",
    "# Others\n",
    "CHECKPOINT_DIR = os.path.join(\"./ckpts/\", ID)\n",
    "CHECKPOINT_NAME = \"ckpt\"\n",
    "OUTPUT_DIR = os.path.join(\"./outputs/\", ID)\n",
    "SAVE_PLOTS = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import torch\n",
    "import warnings\n",
    "from IPython import get_ipython\n",
    "\n",
    "\n",
    "# Check if CUDA is available\n",
    "if torch.cuda.is_available():\n",
    "    gpus = torch.cuda.device_count()\n",
    "    DEVICE_ID = DEVICE_ID if DEVICE_ID < gpus else 0\n",
    "    torch.cuda.set_device(DEVICE_ID)\n",
    "    if DISTRIBUTED:\n",
    "        DEVICE_IDS = [id for id in DEVICE_IDS if id < gpus]\n",
    "    else:\n",
    "        for device_id in DEVICE_IDS:\n",
    "            if device_id >= gpus:\n",
    "                raise ValueError(f\"GPU {device_id} is not available.\")\n",
    "else:\n",
    "    DEVICE = \"cpu\"\n",
    "    DEVICE_ID = None\n",
    "\n",
    "if DISTRIBUTED:\n",
    "    print(f\"Rank {RANK} Using distributed training with devices: {DEVICE_IDS}\")\n",
    "else:\n",
    "    print(f\"Using device id: {DEVICE_ID}\")\n",
    "\n",
    "os.environ[\"OMP_NUM_THREADS\"] = str(OMP_NUM_THREADS)\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import get_ipython\n",
    "\n",
    "from utils.dataset import DatasetToolConfig, DatasetTool\n",
    "\n",
    "\n",
    "def test_datasets():\n",
    "    ipy = get_ipython()\n",
    "    if ipy is not None:\n",
    "        ipy.magic(\"matplotlib inline\")\n",
    "        import matplotlib.pyplot as plt\n",
    "\n",
    "        dt_cfg = DatasetToolConfig(\n",
    "            id2word_path=DS_ID2WORD_PATH,\n",
    "            vocab_path=DS_VOCAB_PATH,\n",
    "            word2id_path=DS_WORD2ID_PATH,\n",
    "            image_path=DS_IMAGE_PATH,\n",
    "            text2img_path=DS_TEXT2IMG_PATH,\n",
    "            test_data_path=DS_TEST_DATA_PATH,\n",
    "        )\n",
    "        dt = DatasetTool(dt_cfg)\n",
    "\n",
    "        train_loader = dt.get_train_loader(\n",
    "            16,\n",
    "            IMAGE_SIZE,\n",
    "            repeats=DATASET_REPETITIONS,\n",
    "            shuffle=True,\n",
    "            pin_memory=True,\n",
    "            num_workers=4,\n",
    "            rank=RANK,\n",
    "            world_size=WORLD_SIZE,\n",
    "            distributed=DISTRIBUTED,\n",
    "        )\n",
    "\n",
    "        images, captions = next(iter(train_loader))\n",
    "        plt.figure(figsize=(16, 4))\n",
    "        for i, image in enumerate(images):\n",
    "            plt.subplot(2, 8, i + 1)\n",
    "            plt.imshow(image.permute(1, 2, 0))\n",
    "            plt.title(captions[i][:12])\n",
    "            plt.axis(\"off\")\n",
    "            plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "# test_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from datetime import datetime\n",
    "import logging\n",
    "\n",
    "import torch\n",
    "import torch.distributed as dist\n",
    "\n",
    "from utils.dataset import DatasetToolConfig, DatasetTool\n",
    "from models.sd import VAEModel, VAEModelConfig\n",
    "from utils.checkpoint import load_checkpoint, save_checkpoint\n",
    "from utils.distributed import init_distributed, cleanup_distributed\n",
    "\n",
    "cfg = VAEModelConfig(\n",
    "    image_height=IMAGE_SIZE,\n",
    "    image_width=IMAGE_SIZE,\n",
    "    latent_height=IMAGE_SIZE // 8,\n",
    "    latent_width=IMAGE_SIZE // 8,\n",
    "    latent_dim=LATENT_DIM,\n",
    "    num_heads=NUM_HEADS,\n",
    "    vae_scale=VAE_SCALE,\n",
    "    vae_beta=VAE_BETA,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    weight_decay=WEIGHT_DECAY,\n",
    "    mixed_precision=MIXED_PRECISION,\n",
    "    device=DEVICE,\n",
    "    device_type=\"cuda\" if DEVICE != \"cpu\" else \"cpu\",\n",
    "    rank=RANK,\n",
    "    world_size=WORLD_SIZE,\n",
    "    device_ids=DEVICE_IDS,\n",
    "    distributed=DISTRIBUTED,\n",
    ")\n",
    "ds_cfg = DatasetToolConfig(\n",
    "    id2word_path=DS_ID2WORD_PATH,\n",
    "    vocab_path=DS_VOCAB_PATH,\n",
    "    word2id_path=DS_WORD2ID_PATH,\n",
    "    image_path=DS_IMAGE_PATH,\n",
    "    text2img_path=DS_TEXT2IMG_PATH,\n",
    "    test_data_path=DS_TEST_DATA_PATH,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    if DISTRIBUTED:\n",
    "        # Initialize\n",
    "        init_distributed(RANK, WORLD_SIZE)\n",
    "        torch.cuda.set_device(DEVICE_IDS[RANK])\n",
    "\n",
    "    start_ts = time.perf_counter()\n",
    "    model = VAEModel(cfg)\n",
    "    print(f\"Model created in {time.perf_counter() - start_ts:.2f}s\")\n",
    "\n",
    "    checkpoint = load_checkpoint(\n",
    "        CHECKPOINT_DIR, CHECKPOINT_NAME, epoch=START_EPOCH, device=DEVICE\n",
    "    )\n",
    "    if checkpoint is not None:\n",
    "        model.load_checkpoint(checkpoint)\n",
    "\n",
    "    ds_tool = DatasetTool(ds_cfg)\n",
    "    train_loader, val_loader = ds_tool.get_train_val_loader(\n",
    "        BATCH_SIZE,\n",
    "        IMAGE_SIZE,\n",
    "        repeats=DATASET_REPETITIONS,\n",
    "        shuffle=True,\n",
    "        pin_memory=True,\n",
    "        num_workers=4,\n",
    "        rank=RANK,\n",
    "        world_size=WORLD_SIZE,\n",
    "        distributed=DISTRIBUTED,\n",
    "    )\n",
    "\n",
    "    for epoch in range(START_EPOCH + 1, EPOCHS + START_EPOCH + 1):\n",
    "        print(\n",
    "            \"{}, epoch {:3d}/{:3d}\".format(\n",
    "                datetime.now(), epoch, EPOCHS + START_EPOCH\n",
    "            )\n",
    "        )\n",
    "        epoch_train_metrics = torch.zeros(1).to(DEVICE)\n",
    "        epoch_val_metrics = torch.zeros(1).to(DEVICE)\n",
    "\n",
    "        start_ts = time.perf_counter()\n",
    "\n",
    "        if DISTRIBUTED:\n",
    "            train_loader.sampler.set_epoch(epoch)\n",
    "        for _idx, (images, _) in enumerate(train_loader):\n",
    "            idx = _idx + 1\n",
    "            train_metrics = model.train_step(images)\n",
    "            epoch_train_metrics += torch.tensor([train_metrics[\"loss\"]]).to(\n",
    "                DEVICE\n",
    "            )\n",
    "            if idx % 20 == 0:\n",
    "                print(\n",
    "                    \"rank {:2d}, train epoch {:3d}/{:3d}, batch {:4d}/{:4d}, loss: {:.4f}\".format(\n",
    "                        RANK,\n",
    "                        epoch,\n",
    "                        EPOCHS + START_EPOCH,\n",
    "                        idx,\n",
    "                        len(train_loader),\n",
    "                        train_metrics[\"loss\"],\n",
    "                    )\n",
    "                )\n",
    "\n",
    "        # Save checkpoint\n",
    "        if RANK == 0:\n",
    "            save_checkpoint(\n",
    "                epoch,\n",
    "                model.checkpoint(),\n",
    "                CHECKPOINT_DIR,\n",
    "                CHECKPOINT_NAME,\n",
    "            )\n",
    "\n",
    "        if DISTRIBUTED:\n",
    "            val_loader.sampler.set_epoch(epoch)\n",
    "        for _idx, (images, _) in enumerate(val_loader):\n",
    "            idx = _idx + 1\n",
    "            val_metrics = model.test_step(images)\n",
    "            epoch_val_metrics += torch.tensor([val_metrics[\"loss\"]]).to(DEVICE)\n",
    "\n",
    "        if DISTRIBUTED:\n",
    "            dist.all_reduce(epoch_train_metrics, op=dist.ReduceOp.AVG)\n",
    "\n",
    "        # Print metrics\n",
    "        if RANK == 0:\n",
    "            avg_train_metrics = epoch_train_metrics / len(train_loader)\n",
    "            epoch_train_metrics.zero_()\n",
    "            print(\n",
    "                \"rank {:2d}, epoch {:3d}/{:3d}, loss: {:.4f}, time: {:.2f}s\".format(\n",
    "                    RANK,\n",
    "                    epoch,\n",
    "                    EPOCHS + START_EPOCH,\n",
    "                    avg_train_metrics[0],\n",
    "                    time.perf_counter() - start_ts,\n",
    "                )\n",
    "            )\n",
    "\n",
    "        if RANK == 0 and epoch % PLOT_EVERY == 0:\n",
    "            if DISTRIBUTED:\n",
    "                val_loader.sampler.set_epoch(epoch)\n",
    "            images, _ = next(iter(val_loader))\n",
    "            model.plot_images(\n",
    "                images,\n",
    "                save=SAVE_PLOTS,\n",
    "                output_dir=OUTPUT_DIR,\n",
    "                epoch=epoch,\n",
    "            )\n",
    "\n",
    "        if DISTRIBUTED:\n",
    "            dist.barrier()\n",
    "\n",
    "    if DISTRIBUTED:\n",
    "        # Cleanup\n",
    "        cleanup_distributed()\n",
    "\n",
    "\n",
    "if EPOCHS > 0:\n",
    "    train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
