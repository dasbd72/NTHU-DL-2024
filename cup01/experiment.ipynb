{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "import dotenv\n",
    "import mlflow\n",
    "import logging\n",
    "from utils import (\n",
    "    test_mlflow_connection,\n",
    "    mlflow_cross_validate,\n",
    ")\n",
    "\n",
    "MLFLOW_ENDPOINT = \"http://10.121.252.164:5001\"\n",
    "MLFLOW_EXPERIMENT_NAME = \"datalab_cup01\"\n",
    "\n",
    "dotenv.load_dotenv(\".env\")\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "test_mlflow_connection(MLFLOW_ENDPOINT)\n",
    "\n",
    "\n",
    "def mlflow_setup():\n",
    "    mlflow_logger = logging.getLogger(\"mlflow\")\n",
    "    mlflow_logger.setLevel(logging.ERROR)\n",
    "    mlflow.set_tracking_uri(MLFLOW_ENDPOINT)\n",
    "    mlflow.set_experiment(MLFLOW_EXPERIMENT_NAME)\n",
    "    mlflow.autolog(log_datasets=False, silent=True)\n",
    "\n",
    "\n",
    "def cross_validate(\n",
    "    clf,\n",
    "    X,\n",
    "    y,\n",
    "    columns=None,\n",
    "    n_folds=5,\n",
    "    seed=42,\n",
    "    verbose=1,\n",
    "    n_jobs=-1,\n",
    "    parent_run: mlflow.ActiveRun = None,\n",
    "):\n",
    "    return mlflow_cross_validate(\n",
    "        clf,\n",
    "        X,\n",
    "        y,\n",
    "        columns=columns,\n",
    "        n_folds=n_folds,\n",
    "        seed=seed,\n",
    "        verbose=verbose,\n",
    "        n_jobs=n_jobs,\n",
    "        mlflow_parent_run=parent_run,\n",
    "        mlflow_setup=mlflow_setup,\n",
    "    )\n",
    "\n",
    "\n",
    "mlflow_setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from features import Features\n",
    "from utils.plotting import plot_correlations\n",
    "\n",
    "features = Features(\n",
    "    train_path=\"data/train.parquet\",\n",
    "    test_path=\"data/test.parquet\",\n",
    "    onehot_weekday=False,\n",
    "    onehot_month=False,\n",
    "    category_max_features=10000,\n",
    "    category_train_min=3,\n",
    "    category_test_min=2,\n",
    ")\n",
    "plot = True\n",
    "\n",
    "features.extract_info()\n",
    "X_info = features.X_info\n",
    "y = features.y\n",
    "df_test = features.df_test\n",
    "X_test_info = features.X_test_info\n",
    "print(\"X_info shape: \", X_info.shape)\n",
    "print(\"X_test_info shape: \", X_test_info.shape)\n",
    "if plot:\n",
    "    plot_correlations(X_info, y)\n",
    "\n",
    "X_info = X_info.fillna(X_info.mean())\n",
    "X_test_info = X_test_info.fillna(X_test_info.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Clone\n",
    "X_info_filtered = X_info.copy()\n",
    "X_test_info_filtered = X_test_info.copy()\n",
    "columns = X_info_filtered.columns.tolist()\n",
    "\n",
    "# Filter out columns\n",
    "regex_filters = [\n",
    "    # r\"^datetime_\",  # All datetime columns\n",
    "    # r\"^datetime_month_\",\n",
    "    # r\"^datetime_weekday_\",\n",
    "    # r\"^datetime_year\",\n",
    "    # r\"^datetime_day\",\n",
    "    # r\"^datetime_hour\",\n",
    "    r\"^datetime_minute\",  # Overfitting\n",
    "    r\"^datetime_second\",  # Overfitting\n",
    "    r\"^sel_\",  # All selectors\n",
    "    # r\"^sel_.+(?<!_token)_count$\",\n",
    "    # r\"^sel_.+(?<!_non_stop)(?<!_unique)_token_count$\",\n",
    "    # r\"^sel_.+(?<!_non_stop)_unique_token_count$\",\n",
    "    # r\"^sel_.+_non_stop_token_count$\",\n",
    "    # r\"^sel_.+_non_stop_unique_token_count$\",\n",
    "    # r\"^sel_.+_pos$\",\n",
    "    # r\"^sel_.+_neg$\", # Very Bad\n",
    "    # r\"^sel_.+_neu$\",\n",
    "    # r\"^sel_.+_subjectivity$\",\n",
    "    # r\"^sel_.+_polarity$\", # Very Good\n",
    "    # r\"^sel_.+_compound$\", # Very Good\n",
    "    # r\"^sel_.+_readability$\", # Very Bad\n",
    "    # r\"^sel_html_\",\n",
    "    # r\"^sel_h1_\",\n",
    "    # r\"^sel_h2_\",\n",
    "    # r\"^sel_p_\",\n",
    "    # r\"^sel_a_\",\n",
    "    # r\"^sel_div_\",\n",
    "    # r\"^sel_footer_a_\",\n",
    "    # r\"^sel_section_\",\n",
    "    # r\"^sel_instagram_\",\n",
    "    # r\"^sel_twitter_\",\n",
    "    # r\"^sel_img_\",\n",
    "    # r\"^sel_iframe_\",\n",
    "    # r\"^sel_video_\",\n",
    "    # r\"^channel_\",  # All channel columns\n",
    "    # r\"^category_\",  # All category columns\n",
    "]\n",
    "\n",
    "# Filter columns using regex\n",
    "filtered_columns = [\n",
    "    col\n",
    "    for col in columns\n",
    "    if all([not re.match(regex, col) for regex in regex_filters])\n",
    "]\n",
    "\n",
    "X_info_filtered = X_info_filtered[filtered_columns]\n",
    "X_test_info_filtered = X_test_info_filtered[filtered_columns]\n",
    "\n",
    "top_n_categories = False\n",
    "top_n_categories_count = 50\n",
    "if top_n_categories:\n",
    "    # Remove all category columns\n",
    "    category_columns = [col for col in columns if col.startswith(\"category_\")]\n",
    "    X_info_filtered = X_info_filtered.drop(columns=category_columns)\n",
    "    X_test_info_filtered = X_test_info_filtered.drop(columns=category_columns)\n",
    "\n",
    "    # Get top n category columns\n",
    "    top_category_columns = (\n",
    "        X_info[category_columns]\n",
    "        .corrwith(pd.Series(y))\n",
    "        .sort_values(\n",
    "            ascending=False,\n",
    "            key=lambda x: np.abs(x),\n",
    "        )\n",
    "        .head(top_n_categories_count)\n",
    "        .index.tolist()\n",
    "    )\n",
    "\n",
    "    # Put top n category columns back\n",
    "    X_info_filtered = pd.concat(\n",
    "        [X_info_filtered, X_info[top_category_columns]],\n",
    "        axis=1,\n",
    "    )\n",
    "    X_test_info_filtered = pd.concat(\n",
    "        [X_test_info_filtered, X_test_info[top_category_columns]],\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "print(\"X_info_filtered shape: \", X_info_filtered.shape)\n",
    "print(\"X_test_info_filtered shape: \", X_test_info_filtered.shape)\n",
    "if plot:\n",
    "    plot_correlations(X_info_filtered, y)\n",
    "\n",
    "# Scale data\n",
    "columns = X_info_filtered.columns.tolist()\n",
    "X = X_info_filtered.values\n",
    "X_test = X_test_info_filtered.values\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "import mlflow\n",
    "\n",
    "\n",
    "def save_prediction(id, y_pred, name, mlflow_logging=True):\n",
    "    df_pred = pd.DataFrame({\"Id\": id, \"Popularity\": y_pred})\n",
    "    filepath = \"output/minimal/{}.{}.csv\".format(\n",
    "        name, datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    )\n",
    "    os.makedirs(os.path.dirname(filepath), exist_ok=True)\n",
    "    df_pred.to_csv(filepath, index=False)\n",
    "    print(\"Saved prediction to \", filepath)\n",
    "    if mlflow_logging:\n",
    "        mlflow.log_artifact(filepath, \"predictions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "cb_params = {\n",
    "    \"loss_function\": \"Logloss\",\n",
    "    \"eval_metric\": \"AUC\",\n",
    "    \"silent\": True,\n",
    "    \"thread_count\": os.cpu_count(),\n",
    "    \"random_seed\": 42,  # Ensures reproducibility\n",
    "    \"n_estimators\": 200,\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"depth\": 6,\n",
    "    \"l2_leaf_reg\": 10.0,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "import mlflow\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "catboost_model_tags = {\n",
    "    \"model\": \"CatBoostClassifier\",\n",
    "    \"tuning\": \"false\",\n",
    "    \"final\": \"false\",\n",
    "}\n",
    "\n",
    "n_folds = 5\n",
    "with mlflow.start_run(\n",
    "    run_name=\"minimal-catboost-cv\", tags=catboost_model_tags\n",
    ") as run:\n",
    "    _cb_params = {\n",
    "        **cb_params,\n",
    "        \"thread_count\": max(os.cpu_count() // n_folds, 1),\n",
    "    }\n",
    "    cb_clf = CatBoostClassifier(**_cb_params)\n",
    "    cross_validate(\n",
    "        cb_clf, X, y, columns=columns, n_folds=n_folds, parent_run=run\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "import mlflow\n",
    "import mlflow.catboost\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "with mlflow.start_run(run_name=\"minimal-catboost\") as run:\n",
    "    print(\"Run ID: \", run.info.run_id)\n",
    "    mlflow.set_tags(cb_model_tags)\n",
    "    for k, v in cb_params.items():\n",
    "        mlflow.log_param(k, v)\n",
    "    cb_clf = CatBoostClassifier(**cb_params)\n",
    "    cb_clf.fit(X, y)\n",
    "    mlflow.catboost.log_model(cb_clf, \"model\")\n",
    "    train_auc = roc_auc_score(y, cb_clf.predict_proba(X)[:, 1])\n",
    "    mlflow.log_metric(\"train_auc\", train_auc)\n",
    "    print(\"AUC train: {:.5f}\".format(train_auc))\n",
    "\n",
    "    y_test = cb_clf.predict_proba(X_test)[:, 1]\n",
    "    save_prediction(df_test[\"Id\"], y_test, \"catboost\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params = {\n",
    "    \"booster\": \"gbtree\",\n",
    "    \"objective\": \"binary:logistic\",\n",
    "    \"eval_metric\": \"auc\",\n",
    "    \"n_jobs\": -1,\n",
    "    \"verbosity\": 0,\n",
    "    \"random_state\": 42,\n",
    "    \"n_estimators\": 300,\n",
    "    \"max_depth\": 8,\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"reg_lambda\": 20.0,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "import os\n",
    "import mlflow\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "xgb_model_tags = {\n",
    "    \"model\": \"XGBClassifier\",\n",
    "    \"tuning\": \"false\",\n",
    "    \"final\": \"false\",\n",
    "}\n",
    "\n",
    "n_folds = 5\n",
    "with mlflow.start_run(\n",
    "    run_name=\"minimal-xgboost-cv\",\n",
    "    tags=xgb_model_tags,\n",
    ") as run:\n",
    "    _xgb_params = {**xgb_params, \"n_jobs\": max(os.cpu_count() // n_folds, 1)}\n",
    "    xgb_clf = XGBClassifier(**_xgb_params)\n",
    "    cv_results = cross_validate(\n",
    "        xgb_clf, X, y, columns=columns, n_folds=n_folds, parent_run=run\n",
    "    )\n",
    "\n",
    "# xgb_param_grids = {\n",
    "#     \"max_depth\": [4, 6, 8],\n",
    "#     \"learning_rate\": [0.005, 0.01, 0.1],\n",
    "#     \"n_estimators\": [100, 200, 300],\n",
    "# }\n",
    "# xgb_model_tags = {\n",
    "#     \"model\": \"XGBClassifier\",\n",
    "#     \"tuning\": \"true\",\n",
    "#     \"final\": \"false\",\n",
    "# }\n",
    "\n",
    "# n_folds = 5\n",
    "# with mlflow.start_run(\n",
    "#     run_name=\"minimal-xgboost-gridsearch-cv\", tags=xgb_model_tags\n",
    "# ) as run:\n",
    "#     mlflow.log_params(xgb_param_grids)\n",
    "#     param_grids = ParameterGrid(xgb_param_grids)\n",
    "#     best_params = None\n",
    "#     best_val_auc = 0\n",
    "#     for params in param_grids:\n",
    "#         with mlflow.start_run(\n",
    "#             run_name=\"minimal-xgboost-child-cv\",\n",
    "#             nested=True,\n",
    "#             tags=xgb_model_tags,\n",
    "#         ) as nested_run:\n",
    "#             _xgb_params = {**xgb_params, **params}\n",
    "#             mlflow.log_params(_xgb_params)\n",
    "#             xgb_clf = XGBClassifier(**_xgb_params)\n",
    "#             cv_results = cross_validate(\n",
    "#                 xgb_clf,\n",
    "#                 X,\n",
    "#                 y,\n",
    "#                 n_folds=n_folds,\n",
    "#                 n_jobs=n_folds,\n",
    "#                 verbose=0,\n",
    "#                 parent_run=nested_run,\n",
    "#             )\n",
    "#             train_auc = cv_results[\"train_auc\"].mean()\n",
    "#             val_auc = cv_results[\"val_auc\"].mean()\n",
    "#             if val_auc > best_val_auc:\n",
    "#                 best_val_auc = val_auc\n",
    "#                 best_params = _xgb_params\n",
    "\n",
    "#     print(\"Best params: \", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "import mlflow\n",
    "\n",
    "xgb_model_tags = {\n",
    "    \"model\": \"XGBClassifier\",\n",
    "    \"tuning\": \"false\",\n",
    "    \"final\": \"true\",\n",
    "}\n",
    "\n",
    "with mlflow.start_run(\n",
    "    run_name=\"minimal-xgboost\",\n",
    "    tags=xgb_model_tags,\n",
    ") as run:\n",
    "    print(\"Run ID: \", run.info.run_id)\n",
    "    mlflow.log_param(\"columns\", columns)\n",
    "    mlflow.log_params(xgb_params)\n",
    "    xgb_clf = XGBClassifier(**xgb_params)\n",
    "    xgb_clf.fit(X, y)\n",
    "    train_auc = roc_auc_score(y, xgb_clf.predict_proba(X)[:, 1])\n",
    "    mlflow.log_metric(\"train_auc\", train_auc)\n",
    "    print(\"AUC train: {:.5f}\".format(train_auc))\n",
    "\n",
    "    y_test = xgb_clf.predict_proba(X_test)[:, 1]\n",
    "    save_prediction(df_test[\"Id\"], y_test, \"xgboost\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_params = {\n",
    "    \"boosting_type\": \"gbdt\",  # Gradient boosting decision tree\n",
    "    \"objective\": \"binary\",  # Binary classification\n",
    "    \"metric\": \"auc\",  # Use AUC for evaluation\n",
    "    \"verbosity\": -1,  # Suppress excessive logs,\n",
    "    \"n_jobs\": 6,\n",
    "    \"random_state\": 42,\n",
    "    \"num_leaves\": 31,  # Maximum number of leaves in one tree\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"n_estimators\": 500,\n",
    "    \"max_depth\": 8,\n",
    "    \"reg_lambda\": 10.0,  # Equivalent to l2 regularization\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "import mlflow\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "lgbm_model_tags = {\n",
    "    \"model\": \"LGBMClassifier\",\n",
    "    \"tuning\": \"false\",\n",
    "    \"final\": \"false\",\n",
    "}\n",
    "\n",
    "n_folds = 5\n",
    "with mlflow.start_run(\n",
    "    run_name=\"minimal-lightgbm-cv\", tags=lgbm_model_tags\n",
    ") as run:\n",
    "    _lgbm_params = {**lgbm_params, \"n_jobs\": max(os.cpu_count() // n_folds, 1)}\n",
    "    lgbm_clf = LGBMClassifier(**_lgbm_params)\n",
    "    cv_results = cross_validate(\n",
    "        lgbm_clf, X, y, columns=columns, n_folds=n_folds, parent_run=run\n",
    "    )\n",
    "\n",
    "# lgbm_param_grids = {\n",
    "#     \"n_estimators\": [200, 500],\n",
    "#     \"num_leaves\": [31, 63],\n",
    "#     \"max_depth\": [6, 8, 10],\n",
    "#     \"learning_rate\": [0.001, 0.01, 0.1],\n",
    "#     \"reg_lambda\": [1.0, 10.0, 20.0],\n",
    "# }\n",
    "# lgbm_model_tags = {\n",
    "#     \"model\": \"LGBMClassifier\",\n",
    "#     \"tuning\": \"true\",\n",
    "#     \"final\": \"false\",\n",
    "# }\n",
    "\n",
    "# n_folds = 5\n",
    "# with mlflow.start_run(\n",
    "#     run_name=\"minimal-lightgbm-gridsearch-cv\", tags=lgbm_model_tags\n",
    "# ) as run:\n",
    "#     mlflow.log_params(lgbm_param_grids)\n",
    "#     param_grids = ParameterGrid(lgbm_param_grids)\n",
    "#     assert len(param_grids) < 50\n",
    "#     best_params = None\n",
    "#     best_val_auc = 0\n",
    "#     for params in param_grids:\n",
    "#         if params[\"max_depth\"] ** 2 < params[\"num_leaves\"]:\n",
    "#             continue\n",
    "#         with mlflow.start_run(\n",
    "#             run_name=\"minimal-lightgbm-child-cv\",\n",
    "#             nested=True,\n",
    "#             tags=lgbm_model_tags,\n",
    "#         ) as nested_run:\n",
    "#             _lgbm_params = {**lgbm_params, **params}\n",
    "#             mlflow.log_params(_lgbm_params)\n",
    "#             lgbm_clf = LGBMClassifier(**_lgbm_params)\n",
    "#             cv_results = cross_validate(\n",
    "#                 lgbm_clf,\n",
    "#                 X,\n",
    "#                 y,\n",
    "#                 columns=columns,\n",
    "#                 n_folds=n_folds,\n",
    "#                 n_jobs=n_folds,\n",
    "#                 verbose=0,\n",
    "#                 parent_run=nested_run,\n",
    "#             )\n",
    "#             train_auc = cv_results[\"train_auc\"].mean()\n",
    "#             val_auc = cv_results[\"val_auc\"].mean()\n",
    "#             if val_auc > best_val_auc:\n",
    "#                 best_val_auc = val_auc\n",
    "#                 best_params = _lgbm_params\n",
    "\n",
    "#     print(\"Best params: \", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "import mlflow\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "lgbm_model_tags = {\n",
    "    \"model\": \"LGBMClassifier\",\n",
    "    \"tuning\": \"false\",\n",
    "    \"final\": \"true\",\n",
    "}\n",
    "with mlflow.start_run(run_name=\"minimal-lightgbm\", tags=lgbm_model_tags) as run:\n",
    "    print(\"Run ID: \", run.info.run_id)\n",
    "    lgbm_clf = LGBMClassifier(**lgbm_params)\n",
    "    lgbm_clf.fit(X, y)\n",
    "    train_auc = roc_auc_score(y, lgbm_clf.predict_proba(X)[:, 1])\n",
    "    mlflow.log_metric(\"train_auc\", train_auc)\n",
    "    print(\"AUC train: {:.5f}\".format(train_auc))\n",
    "\n",
    "    y_test = lgbm_clf.predict_proba(X_test)[:, 1]\n",
    "    save_prediction(df_test[\"Id\"], y_test, \"lightgbm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "cb_params = {\n",
    "    \"loss_function\": \"Logloss\",\n",
    "    \"eval_metric\": \"AUC\",\n",
    "    \"silent\": True,\n",
    "    \"thread_count\": 6,\n",
    "    \"n_estimators\": 1000,\n",
    "    \"learning_rate\": 0.01,\n",
    "    # \"depth\": 6,\n",
    "    # \"l2_leaf_reg\": 10.0,\n",
    "    # \"random_seed\": 42,  # Ensures reproducibility\n",
    "}\n",
    "xgb_params = {\n",
    "    \"booster\": \"gbtree\",\n",
    "    \"objective\": \"binary:logistic\",\n",
    "    \"eval_metric\": \"auc\",\n",
    "    \"verbosity\": 0,\n",
    "    \"n_jobs\": 6,\n",
    "    # \"random_state\": 42,\n",
    "    \"n_estimators\": 300,\n",
    "    \"max_depth\": 8,\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"reg_lambda\": 20.0,\n",
    "}\n",
    "lgbm_params = {\n",
    "    \"boosting_type\": \"gbdt\",  # Gradient boosting decision tree\n",
    "    \"objective\": \"binary\",  # Binary classification\n",
    "    \"metric\": \"auc\",  # Use AUC for evaluation\n",
    "    \"verbosity\": -1,  # Suppress excessive logs,\n",
    "    \"n_jobs\": 6,\n",
    "    # \"random_state\": 42,\n",
    "    \"num_leaves\": 31,  # Maximum number of leaves in one tree\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"n_estimators\": 500,\n",
    "    \"max_depth\": 8,\n",
    "    \"reg_lambda\": 10.0,  # Equivalent to l2 regularization\n",
    "}\n",
    "\n",
    "estimators = []\n",
    "# estimators.append((\"catboost\", CatBoostClassifier(**cb_params)))\n",
    "# estimators.append((\"xgboost\", XGBClassifier(**xgb_params)))\n",
    "# estimators.append((\"lightgbm\", LGBMClassifier(**lgbm_params)))\n",
    "for i in range(2):\n",
    "    estimators.append((f\"xgboost{i}\", XGBClassifier(**xgb_params)))\n",
    "for i in range(3):\n",
    "    estimators.append((f\"lightgbm{i}\", LGBMClassifier(**lgbm_params)))\n",
    "\n",
    "# Train a voting classifier\n",
    "voting_params = {\n",
    "    \"estimators\": estimators,\n",
    "    \"voting\": \"soft\",\n",
    "    \"n_jobs\": -1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "import mlflow\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "voting_model_tags = {\n",
    "    \"model\": \"VotingClassifier\",\n",
    "    \"tuning\": \"false\",\n",
    "    \"final\": \"false\",\n",
    "}\n",
    "\n",
    "n_folds = 5\n",
    "with mlflow.start_run(\n",
    "    run_name=\"minimal-voting-cv\", tags=voting_model_tags\n",
    ") as run:\n",
    "    _voting_params = {\n",
    "        **voting_params,\n",
    "        \"n_jobs\": max(os.cpu_count() // n_folds, 1),\n",
    "    }\n",
    "    voting_clf = VotingClassifier(**_voting_params)\n",
    "    cv_results = cross_validate(\n",
    "        voting_clf, X, y, n_folds=n_folds, parent_run=run\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "import mlflow\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "voting_model_tags = {\n",
    "    \"model\": \"VotingClassifier\",\n",
    "    \"tuning\": \"false\",\n",
    "    \"final\": \"true\",\n",
    "}\n",
    "\n",
    "with mlflow.start_run(\n",
    "    run_name=\"minimal-voting\", tags=voting_model_tags\n",
    ") as run:\n",
    "    voting_clf.fit(X, y)\n",
    "    train_auc = roc_auc_score(y, voting_clf.predict_proba(X)[:, 1])\n",
    "    mlflow.log_metric(\"train_auc\", train_auc)\n",
    "    print(\"AUC train: {:.5f}\".format(train_auc))\n",
    "    print(\"Run ID: \", run.info.run_id)\n",
    "\n",
    "    y_test = voting_clf.predict_proba(X_test)[:, 1]\n",
    "    save_prediction(df_test[\"Id\"], y_test, \"voting\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
